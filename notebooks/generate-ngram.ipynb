{"metadata":{"kernelspec":{"name":"python395jvsc74a57bd02d972ce83b011c0fbc8bf1befcdd55f31c9249b362a9ff124184ebc36a0909c1","display_name":"Python 3.9.5 64-bit"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.9.5","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"metadata":{"interpreter":{"hash":"2d972ce83b011c0fbc8bf1befcdd55f31c9249b362a9ff124184ebc36a0909c1"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import spacy\n","import json\n","import csv\n","import pickle\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","import matplotlib.pyplot as plt\n","import itertools\n","from tqdm.notebook import tqdm\n","from math import floor\n","from random import shuffle\n","from sklearn.model_selection import train_test_split\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    print(f\"{dirname} contains {len(filenames)} files\")\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-22T10:11:25.341460Z","iopub.execute_input":"2021-05-22T10:11:25.341814Z","iopub.status.idle":"2021-05-22T10:11:37.844937Z","shell.execute_reply.started":"2021-05-22T10:11:25.341741Z","shell.execute_reply":"2021-05-22T10:11:37.843816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GLOBAL SETTINGS"],"metadata":{}},{"cell_type":"code","source":["saved_model_filepath = None # SET TO 'None' if you want to train from scratch!\n","save_model = True\n","test_size = 0.2"],"metadata":{"execution":{"iopub.status.busy":"2021-05-22T10:11:47.370411Z","iopub.execute_input":"2021-05-22T10:11:47.370947Z","iopub.status.idle":"2021-05-22T10:11:47.375611Z","shell.execute_reply.started":"2021-05-22T10:11:47.370912Z","shell.execute_reply":"2021-05-22T10:11:47.374599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# utilities"],"metadata":{}},{"cell_type":"code","source":["import string \n","import re\n","\n","def clean_text(text):\n","    '''\n","    Converts all text to lower case, Removes special characters, emojis and multiple spaces\n","    text - Sentence that needs to be cleaned\n","    '''\n","    text = ''.join([k for k in text if k not in string.punctuation])\n","    text = re.sub('[^A-Za-z0-9]+', ' ', str(text).lower()).strip()\n","    text = re.sub(' +', ' ', text)\n","    emoji_pattern = re.compile(\"[\"\n","                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                               \"]+\", flags=re.UNICODE)\n","    text = emoji_pattern.sub(r'', text)\n","    return text"],"metadata":{"execution":{"iopub.status.busy":"2021-05-22T10:12:00.356313Z","iopub.execute_input":"2021-05-22T10:12:00.356773Z","iopub.status.idle":"2021-05-22T10:12:00.365039Z","shell.execute_reply.started":"2021-05-22T10:12:00.356733Z","shell.execute_reply":"2021-05-22T10:12:00.363851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# load data\n"],"metadata":{}},{"cell_type":"code","source":["def load_train_data():\n","    training_data = []\n","    \n","    # open the csv with id's, data labels, etc. and append the json files to it\n","    files = []\n","    train_dir = '../input/coleridgeinitiative-show-us-the-data/train' # location of the training json files\n","    df = pd.read_csv('../input/coleridgeinitiative-show-us-the-data/train.csv') # location of the training csv file (does not contain the actual texts)\n","    for i in df.index:\n","        file_id = df['Id'][i]\n","        filename = f\"{file_id}.json\"\n","        filepath = os.path.join(train_dir, filename)\n","        with open(filepath) as json_file:\n","            file = json.loads(json_file.read())\n","            files.append(file)\n","    df['file'] = files\n","    \n","    return df\n","\n","df = load_train_data()\n","df.describe()"],"metadata":{"execution":{"iopub.status.busy":"2021-05-22T10:12:27.592910Z","iopub.execute_input":"2021-05-22T10:12:27.593277Z","iopub.status.idle":"2021-05-22T10:14:19.012316Z","shell.execute_reply.started":"2021-05-22T10:12:27.593247Z","shell.execute_reply":"2021-05-22T10:14:19.011173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df['cleaned_label'][20])"],"metadata":{"execution":{"iopub.status.busy":"2021-05-22T10:19:23.432942Z","iopub.execute_input":"2021-05-22T10:19:23.433327Z","iopub.status.idle":"2021-05-22T10:19:23.438648Z","shell.execute_reply.started":"2021-05-22T10:19:23.433296Z","shell.execute_reply":"2021-05-22T10:19:23.437819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train = df[\"file\"]\n","y_train = df[\"dataset_label\"]\n","y_train = [{\n","    \"dataset_label\": df[\"dataset_label\"][index],\n","    \"dataset_title\": df[\"dataset_title\"][index],\n","    \"cleaned_label\": df[\"cleaned_label\"][index]\n","} \n","    for index in y_train.index]\n","\n","print(X_train[:5])\n","print(y_train[:5])"]},{"cell_type":"code","source":["def format_dataframe_for_spacy(xs, ys):\n","    '''\n","    xs - array of samples, where each sample is an array of dictionaries, where each dictionary has a `text` and `section_title` key-value pair\n","    ys - array of strings, where the i'th index is the dataset label corresponding to the i'th sample in `xs`\n","    '''\n","    data = []\n","    pb = tqdm(total=len(xs))\n","    for x, y in zip(xs, ys):\n","        for section in x:\n","            # each section contains a 'section_title' and a 'text' key, for now we only use 'text'\n","            text = section['text']\n","            \n","            # tokenize the text into sentences\n","            sentences = sent_tokenize(text)\n","\n","            # !IMPORTANT TODO: Adding padding to the dataset title removes about 1/3rd of the training data. probably not good\n","            for sentence in sentences:\n","                # Only use a sentence as a training sample IF it contains a dataset label\n","                if y in sentence:\n","                    sample = sentence.replace(y, '<DATASET>')\n","                    data.append(sample)\n","        pb.update(1)\n","    pb.close()\n","    return data\n","\n","spacy_training_data = format_dataframe_for_spacy(X_train, [y[\"dataset_label\"] for y in y_train])\n","print(spacy_training_data[0])"],"metadata":{"execution":{"iopub.status.busy":"2021-05-22T10:19:26.455716Z","iopub.execute_input":"2021-05-22T10:19:26.456274Z","iopub.status.idle":"2021-05-22T10:19:27.697518Z","shell.execute_reply.started":"2021-05-22T10:19:26.456238Z","shell.execute_reply":"2021-05-22T10:19:27.696463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TRAIN_DATA = spacy_training_data\n","print(TRAIN_DATA[0])"],"metadata":{"execution":{"iopub.status.busy":"2021-05-22T10:19:46.132398Z","iopub.execute_input":"2021-05-22T10:19:46.132805Z","iopub.status.idle":"2021-05-22T10:19:46.136546Z","shell.execute_reply.started":"2021-05-22T10:19:46.132769Z","shell.execute_reply":"2021-05-22T10:19:46.135472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","from nltk.util import ngrams\n","from nltk import word_tokenize\n","\n","textdata = TRAIN_DATA[0].split()\n","    \n","def process_text(text):\n","    text = text.lower()\n","    text = text.replace(',', ' ')\n","    text = text.replace('/', ' ')\n","    text = text.replace('(', ' ')\n","    text = text.replace(')', ' ')\n","    text = text.replace('.', ' ')\n","    text = text.replace(';', ' ')\n","    text = text.replace(':', ' ')\n","    text = text.replace('-', ' ')\n"," \n","    # Convert text string to a list of words\n","    return text.split()\n","\n","def generate_ngrams(words_list, n):\n","    ngrams_list = []\n"," \n","    for num in range(0, len(words_list)):\n","        ngram = ' '.join(words_list[num:num + n])\n","        ngrams_list.append(ngram)\n"," \n","    return ngrams_list\n","\n","\n","def getAllNgrams(data, n):\n","    ngrams_Set = []\n","    for index in range(len(data)):\n","        wordList = process_text(data[index])\n","        ngrams = generate_ngrams(wordList, n)\n","        ngrams_Set.append(ngrams)\n","    \n","    return ngrams_Set\n","\n","bigrams_data = getAllNgrams(TRAIN_DATA, 4)\n","# print(bigrams_data[0])\n","\n","total_filtered = []\n","for index in range(len(bigrams_data)):\n","    total_filtered.append([x for x in bigrams_data[index] if '<dataset>' in x])\n","\n","fdist = nltk.FreqDist(list(itertools.chain(*total_filtered))).most_common(20)\n","for k,v in fdist:\n","    print(k.split(' '),v)"],"metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:20:29.293307Z","iopub.execute_input":"2021-05-22T11:20:29.293705Z","iopub.status.idle":"2021-05-22T11:20:33.778672Z","shell.execute_reply.started":"2021-05-22T11:20:29.293670Z","shell.execute_reply":"2021-05-22T11:20:33.777560Z"},"trusted":true,"tags":[]},"execution_count":null,"outputs":[]}]}